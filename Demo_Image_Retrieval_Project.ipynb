{"cells":[{"cell_type":"markdown","metadata":{"id":"tj8v4-FUFyrp"},"source":["# Digital Signal and Image Processing Project - Image Retrieval"]},{"cell_type":"markdown","metadata":{"id":"JYRFsJ1QF1lS"},"source":["# Imports and Dataset"]},{"cell_type":"markdown","metadata":{"id":"TPO8Ysc0M7xU"},"source":["## Imports"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":969,"status":"ok","timestamp":1738716971094,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"7oHSqSgnFgIQ","outputId":"de961e45-76e3-4573-d5aa-2dfe1225b070"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","from ipyfilechooser import FileChooser\n","from IPython.display import display\n","import threading\n","import time\n","import zipfile\n","import shutil\n","import os\n","import numpy as np\n","import random as python_random\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import json\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.utils import load_img, img_to_array\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","from sklearn.neighbors import KDTree\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","from keras.layers import Input, Lambda\n","from keras.optimizers import Adam\n","from keras import backend as K\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Activation\n","from keras.models import Sequential, Model\n","from keras.layers import ZeroPadding2D, Convolution2D, MaxPooling2D, Dropout, Flatten, Activation\n","from keras.optimizers import SGD\n","from keras.utils import to_categorical\n","from keras.preprocessing import image\n","from keras import applications\n","import numpy as np\n","from IPython.core.display import Image\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras import layers, Model\n","from tensorflow.keras.metrics import Metric\n","from scipy.spatial.distance import cdist\n","from sklearn.metrics import confusion_matrix\n","\n","np.random.seed(0)\n","python_random.seed(0)\n","tf.random.set_seed(0)\n","keras.utils.set_random_seed(0)\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"QfPntIqNIViF"},"source":["## Dataset Import and Split\n","\n","The dataset is imported, extracted and divided into train-val-test sets, with a proportion of 60-20-20.\n","\n","The folder \"dataset\" is created which contains 3 sub folders for the 3 splits. The images are still divided by category.\n","\n","Dictionaries are used to map label indices to their corresponding category names and vice versa."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9532,"status":"ok","timestamp":1738716734738,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"dxN-9IN_G5oG"},"outputs":[],"source":["# Transfer dataset, and extract files\n","shutil.copy('/content/drive/My Drive/MammalsDataset.zip', 'MammalsDataset.zip')\n","zipf = zipfile.ZipFile('MammalsDataset.zip')\n","zipf.extractall()\n","zipf.close()\n","\n","os.remove('MammalsDataset.zip') # Delete the copied zip file"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":765,"status":"ok","timestamp":1738716735518,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"5FNN-1skJ8Ju","colab":{"base_uri":"https://localhost:8080/"},"outputId":"803f217b-7059-4644-9cfd-3f39d897b63c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset split completed successfully.\n"]}],"source":["dataset_origin_path = \"mammals\"\n","dataset_path = \"dataset\"\n","train_ratio, val_ratio, test_ratio = 0.6, 0.2, 0.2\n","\n","# Create destination directories\n","for split in ['train', 'val', 'test']:\n","    split_path = os.path.join(dataset_path, split)\n","    os.makedirs(split_path, exist_ok=True)\n","\n","# Iterate through each category (sub-folder)\n","for category in sorted(os.listdir(dataset_origin_path)):\n","    category_path = os.path.join(dataset_origin_path, category)\n","\n","    images = sorted(os.listdir(category_path))\n","    python_random.seed(0)\n","    python_random.shuffle(images)\n","\n","    train_end = int(train_ratio * len(images))\n","    val_end = train_end + int(val_ratio * len(images))\n","\n","    splits = {\n","        'train': images[:train_end],\n","        'val': images[train_end:val_end],\n","        'test': images[val_end:]\n","    }\n","\n","    # Move images to respective directories\n","    for split, split_images in splits.items():\n","        split_category_path = os.path.join(dataset_path, split, category)\n","        os.makedirs(split_category_path, exist_ok=True)\n","\n","        for img in split_images:\n","            shutil.move(os.path.join(category_path, img), os.path.join(split_category_path, img))\n","\n","    # Remove empty category folder\n","    os.rmdir(category_path)\n","\n","# Remove the original dataset folder if empty\n","if not os.listdir(dataset_origin_path):\n","    os.rmdir(dataset_origin_path)\n","\n","print(\"Dataset split completed successfully.\")\n"]},{"cell_type":"markdown","metadata":{"id":"hAwc5A78aJWl"},"source":["Dictionaries are created in order to map label indices to their corresponding category names and vice versa, whenever this will be needed later in the project."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":56,"status":"ok","timestamp":1738716735573,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"FJhGV5OIOOtr"},"outputs":[],"source":["category_names = sorted([d for d in os.listdir(dataset_path + \"/train\") if os.path.isdir(os.path.join(dataset_path + \"/train\", d))])\n","category_to_index = {name: i for i, name in enumerate(category_names)}\n","index_to_category = {i: name for name, i in category_to_index.items()}"]},{"cell_type":"markdown","metadata":{"id":"t6tdr7mcQHL7"},"source":["## Add some demo-testing images"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2134,"status":"ok","timestamp":1738716737657,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"_7hK36GVQOg9"},"outputs":[],"source":["# Create the demo-testing-images directory\n","src = \"/content/drive/My Drive/IR Saves/demo-testing-images\"\n","dst = \"/content/demo-testing-images\"\n","\n","# Rimuove la cartella se esiste già\n","if os.path.exists(dst):\n","    shutil.rmtree(dst)\n","\n","shutil.copytree(src, dst)\n","\n","# rimuovi tutti i file che contengono \".npy\"\n","for filename in os.listdir(dst):\n","    if filename.endswith(\".npy\"):\n","        file_path = os.path.join(dst, filename)\n","        os.remove(file_path)"]},{"cell_type":"markdown","source":["List of images used in demo:"],"metadata":{"id":"-7V1jFXqYBA6"}},{"cell_type":"code","source":["folder_path = \"/content/demo-testing-images\"\n","full_folder = os.path.join(folder_path, \"alpaca\")\n","file_list = [os.path.join(full_folder, f) for f in os.listdir(full_folder) if os.path.isfile(os.path.join(full_folder, f))]"],"metadata":{"id":"LNi9XWiGYAaK","executionInfo":{"status":"ok","timestamp":1738716737749,"user_tz":-60,"elapsed":61,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_file_index(filename):\n","    full_path = os.path.join(full_folder,filename)\n","    print(full_path)\n","    if full_path in file_list:\n","        return file_list.index(full_path)\n","    else:\n","        return None  # Se il file non è trovato, ritorna None"],"metadata":{"id":"19jmKyqmYMEy","executionInfo":{"status":"ok","timestamp":1738716737756,"user_tz":-60,"elapsed":65,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# test if function works\n","filename = \"tigre.jpg\"\n","index = get_file_index(filename)\n","if index is not None:\n","    print(f\"{file_list[index]} = {index}\")\n","else:\n","    print(\"File non trovato!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oT3JokFZYRLB","executionInfo":{"status":"ok","timestamp":1738716737759,"user_tz":-60,"elapsed":45,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"}},"outputId":"3fbadb57-c62b-437b-9be6-663b4d52a255"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/demo-testing-images/alpaca/tigre.jpg\n","/content/demo-testing-images/alpaca/tigre.jpg = 0\n"]}]},{"cell_type":"markdown","metadata":{"id":"DTbZY74AGBlH"},"source":["# Import models & Features"]},{"cell_type":"markdown","metadata":{"id":"Z1bNNd_QpcQw"},"source":["In this section we load our best performing models and setup some functions for retrival."]},{"cell_type":"markdown","metadata":{"id":"C5M255r0MlZS"},"source":["## Functions"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1738716985231,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"U429Ktk3rLDs"},"outputs":[],"source":["def triplet_loss(margin=0.1):\n","    \"\"\"\n","    necessary for loading siames model\n","    \"\"\"\n","    def loss(y_true, y_pred):\n","        anchor, positive, negative = y_pred[:, 0, :], y_pred[:, 1, :], y_pred[:, 2, :]\n","        pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n","        neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n","        loss = tf.maximum(pos_dist - neg_dist + margin, 0.0)\n","        return tf.reduce_mean(loss)\n","\n","    return loss"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":68,"status":"ok","timestamp":1738716985303,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"TR3Z6sPlMmMC"},"outputs":[],"source":["def extract_features(model, root_folder, category_to_index, preprocess_function, image_size=(224, 224)):\n","    \"\"\"\n","    Extract features from images in a root folder organized into subfolders by labels.\n","    Returns the features, the labels, and the corresponding image paths.\n","    \"\"\"\n","    features = []\n","    labels = []\n","    image_paths = []\n","\n","    for category in sorted(os.listdir(root_folder)):\n","        category_path = os.path.join(root_folder, category)\n","        print(\"Processing folder\", category_path)\n","\n","        if os.path.isdir(category_path):\n","            if category not in category_to_index:\n","                print(f\"Skipping folder '{category}' as it is not in the category mapping.\")\n","                continue\n","\n","            label = category_to_index[category]  # Convert category name to label index\n","\n","            image_files = [fname for fname in os.listdir(category_path) if fname.lower().endswith(('jpg', 'jpeg', 'png'))]\n","\n","            for fname in image_files:\n","                image_path = os.path.join(category_path, fname)\n","\n","                image = load_img(image_path, target_size=image_size)\n","                image_array = img_to_array(image)\n","                image_array = preprocess_function(image_array)\n","                image_array = np.expand_dims(image_array, axis=0)\n","\n","                feature = model.predict(image_array, verbose=0)\n","\n","                features.append(feature.flatten())\n","                labels.append(label)\n","                image_paths.append(image_path)\n","\n","    return np.array(features), np.array(labels), image_paths"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1738716985310,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"xH6XngwjO2jg"},"outputs":[],"source":["def load_or_compute_features(model, features_path, labels_path, paths_path, images_folder, category_to_index, preprocess_function=preprocess_input):\n","    \"\"\"\n","    This function loads the saved features, labels and image paths (if available),\n","    otherwise it computes, saves them and returns them.\n","    \"\"\"\n","    # Check if the feature, label, and image path files exist\n","    if os.path.exists(features_path):\n","        # Load the files if they exist\n","        train_features = np.load(features_path)\n","        train_labels = np.load(labels_path)\n","        train_image_paths = list(np.load(paths_path, allow_pickle=True))\n","        print(\"Loaded existing files.\")\n","    else:\n","        # Otherwise, compute them\n","        print(\"Files missing, computing features...\")\n","        train_features, train_labels, train_image_paths = extract_features(model, images_folder, category_to_index, preprocess_function)\n","\n","        # Create the folder if it doesn't exist already\n","        features_save_folder = os.path.dirname(features_path)\n","        if not os.path.exists(features_save_folder):\n","            os.makedirs(features_save_folder)\n","\n","        # Save the computed features, labels, and image paths\n","        np.save(features_path, train_features)\n","        np.save(labels_path, train_labels)\n","        np.save(paths_path, train_image_paths)\n","        print(\"Computed and saved new features.\")\n","\n","    return train_features, train_labels, train_image_paths"]},{"cell_type":"markdown","metadata":{"id":"Csaykny9GF15"},"source":["## Loading MobileNet model & features\n","\n","In following section we laod mobileNet model and retrive it's previosly computed features, in this way we can later process input images as queries"]},{"cell_type":"markdown","metadata":{"id":"m3yNB3z0tgOI"},"source":["### Loading model"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":1334,"status":"ok","timestamp":1738716986643,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"Atvt8KelGEN4"},"outputs":[],"source":["# Load of MobileNetV2 without the top layer\n","mobilenet = MobileNetV2(weights=\"imagenet\", include_top=False, pooling=\"avg\", input_shape=(224, 224, 3))"]},{"cell_type":"markdown","metadata":{"id":"Ni6QghJmtiOC"},"source":["### Loading features"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":162,"status":"ok","timestamp":1738716986776,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"GxSwQJflIwRz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"da98f447-a1a7-4da4-cba4-ddfdd3c86271"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded existing files.\n"]}],"source":["dataset_train_path = dataset_path + \"/train\"\n","prefix = \"/content/drive/My Drive/\" #\"\"\n","train_features_path = prefix + \"IR Saves/Pre-Trained Approach/train_features.npy\"\n","train_labels_path = prefix + \"IR Saves/Pre-Trained Approach/train_labels.npy\"\n","train_image_names_path = prefix + \"IR Saves/Pre-Trained Approach/train_image_names.npy\"\n","\n","train_features, train_labels, train_image_paths = load_or_compute_features(mobilenet, train_features_path, train_labels_path, train_image_names_path, dataset_train_path, category_to_index)"]},{"cell_type":"code","source":["demo_path = \"demo-testing-images\"\n","test_features_path = prefix + \"IR Saves/demo-testing-images/test_features_1.npy\"\n","test_labels_path = prefix + \"IR Saves/demo-testing-images/test_labels_1.npy\"\n","test_image_names_path = prefix + \"IR Saves/demo-testing-images/test_image_names_1.npy\"\n","\n","test_features, test_labels, test_image_paths = load_or_compute_features(mobilenet, test_features_path, test_labels_path, test_image_names_path, demo_path, category_to_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8Q2RcrneDkf","executionInfo":{"status":"ok","timestamp":1738716986814,"user_tz":-60,"elapsed":36,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"}},"outputId":"7b3e05cc-35ec-4b55-959c-ab9f3cc560d0"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded existing files.\n"]}]},{"cell_type":"markdown","metadata":{"id":"38GQ6qPtrWIg"},"source":["## Loading best siamese model & features\n","\n","In following section we laod siamese model with triplette loss and retrive it's previosly computed features. In this way we can later process input images as queries"]},{"cell_type":"markdown","metadata":{"id":"6OVAncjItkdx"},"source":["### Loading model"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":283,"status":"ok","timestamp":1738716987096,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"sxLdcdBOz67i","colab":{"base_uri":"https://localhost:8080/"},"outputId":"07b64e63-2506-4a41-dad5-e3608651f0f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Models loaded successfully from Google Drive.\n"]}],"source":["# Define the load/save path (the folder)\n","model_folder = \"/content/drive/My Drive/IR Saves/SiameseNetwork Approach\"\n","\n","# Create the folder if it doesn't exist\n","os.makedirs(model_folder, exist_ok=True)\n","\n","# Define the full file paths\n","siamese_model_file = os.path.join(model_folder, \"siamese_model2.keras\")\n","encoder_model_file = os.path.join(model_folder, \"encoder_model2.keras\")\n","\n","# Check if model files exist\n","if os.path.exists(siamese_model_file) and os.path.exists(encoder_model_file):\n","    # Load the models\n","    siamese_model2 = keras.models.load_model(siamese_model_file, custom_objects={'loss': triplet_loss()},safe_mode=False)\n","    encoder2 = keras.models.load_model(encoder_model_file,safe_mode=False)\n","    print(\"Models loaded successfully from Google Drive.\")\n","else:\n","    # Build and train the models\n","    print(\"Models not found. Please upload files to Drive...\")"]},{"cell_type":"markdown","metadata":{"id":"02s5eL9wtmO5"},"source":["### Loading features"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1738716987130,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"XkvbC2Yrz67j"},"outputs":[],"source":["prefix = \"/content/drive/My Drive/\" #"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":118,"status":"ok","timestamp":1738716987251,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"Xftk0u8mz67k","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae8c3486-3ef9-421a-d9c6-aabe8f0daf34"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded existing files.\n"]}],"source":["dataset_train_path = dataset_path + \"/train\"\n","train_features_path = prefix+\"IR Saves/SiameseNetwork2 Approach/train_features.npy\"\n","train_labels_path = prefix+\"IR Saves/SiameseNetwork2 Approach/train_labels.npy\"\n","train_image_names_path = prefix+\"IR Saves/SiameseNetwork2 Approach/train_image_names.npy\"\n","\n","train_features_siamese2 , train_labels_siamese2, train_image_paths_siamese2 = load_or_compute_features(encoder2, train_features_path, train_labels_path, train_image_names_path, dataset_train_path, category_to_index)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":247,"status":"error","timestamp":1738716987496,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"i4n2HoQez67k","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"134cc48c-382c-4894-8e79-86b136c59e26"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files missing, computing features...\n","Processing folder demo-testing-images/alpaca\n"]},{"output_type":"error","ename":"NameError","evalue":"Exception encountered when calling Lambda.call().\n\n\u001b[1mname 'tf' is not defined\u001b[0m\n\nArguments received by Lambda.call():\n  • inputs=tf.Tensor(shape=(1, 128), dtype=float32)\n  • mask=None\n  • training=False","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-7b7441b090de>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_image_names_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"IR Saves/demo-testing-images/test_image_names_2.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_features_siamese2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels_siamese2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image_paths_siamese2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_or_compute_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image_names_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_test_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-b3a74040e0ba>\u001b[0m in \u001b[0;36mload_or_compute_features\u001b[0;34m(model, features_path, labels_path, paths_path, images_folder, category_to_index, preprocess_function)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Otherwise, compute them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files missing, computing features...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_image_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_to_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Create the folder if it doesn't exist already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-8ddb9b68c4b4>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(model, root_folder, category_to_index, preprocess_function, image_size)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mimage_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/python_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: Exception encountered when calling Lambda.call().\n\n\u001b[1mname 'tf' is not defined\u001b[0m\n\nArguments received by Lambda.call():\n  • inputs=tf.Tensor(shape=(1, 128), dtype=float32)\n  • mask=None\n  • training=False"]}],"source":["dataset_test_path = \"demo-testing-images\"\n","test_features_path= prefix + \"IR Saves/demo-testing-images/test_features_2.npy\"\n","test_labels_path = prefix + \"IR Saves/demo-testing-images/test_labels_2.npy\"\n","test_image_names_path = prefix + \"IR Saves/demo-testing-images/test_image_names_2.npy\"\n","\n","test_features_siamese2, test_labels_siamese2, test_image_paths_siamese2 = load_or_compute_features(encoder2, test_features_path, test_labels_path, test_image_names_path, dataset_test_path, category_to_index)"]},{"cell_type":"markdown","metadata":{"id":"MrOaM3mcGKpi"},"source":["# Image Retrieval\n","This section creates the kd-trees, those are use to navigate trough feateures map and find nearest query images. In this way we can see how the features processed from each model (for input image) can be associated with previously evaluated feateures."]},{"cell_type":"markdown","metadata":{"id":"mtxEqGHkx7-B"},"source":["Select here which image you would like to load:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2471,"status":"aborted","timestamp":1738716987576,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"W-EgaLDcx68F"},"outputs":[],"source":["test_image_indices = [get_file_index(\"tigre.jpg\")] # CHANGE IMAGES HERE"]},{"cell_type":"code","source":["test_image_indices"],"metadata":{"id":"FH9pIkwegLZz","executionInfo":{"status":"aborted","timestamp":1738716987579,"user_tz":-60,"elapsed":2472,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"feokLf1Glsin"},"source":["## Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2648,"status":"aborted","timestamp":1738716987756,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"1NSGZhEKluBw"},"outputs":[],"source":["def print_retrieved_images(train_image_paths, test_image_paths, test_image_indices, query_indexes, query_distances):\n","    \"\"\"\n","    Plots the query image and its k nearest neighbors for each test image.\n","    \"\"\"\n","    # Number of test images to plot\n","    num_test_images = len(test_image_indices)\n","\n","    # Number of nearest neighbors to display\n","    k = len(query_indexes[0])\n","\n","    # Adjust the figsize dynamically based on the number of images to display horizontally\n","    fig_width = 3 * (k + 1)  # 1 for the query image and k for neighbors\n","    fig_height = 3 * num_test_images  # 3 units of height per image row\n","\n","    # Set up the plot with multiple rows (one for each test image) and (k + 1) columns (1 for the query image and k for neighbors)\n","    fig, axes = plt.subplots(num_test_images, k + 1, figsize=(fig_width, fig_height))\n","\n","    # Loop over each test image index\n","    for i, test_image_index in enumerate(test_image_indices):\n","        # Get the test image\n","        test_image_path = test_image_paths[test_image_index]\n","        test_image = load_img(test_image_path)\n","\n","        # Extract category (folder name) and image name for the test image\n","        test_image_category = os.path.basename(os.path.dirname(test_image_path))\n","        test_image_name = os.path.basename(test_image_path)\n","\n","\n","        if (len(test_image_indices)!=1):\n","            # Plot the test image (query)\n","            axes[i, 0].imshow(test_image)\n","            axes[i, 0].set_title(f\"Query:\\n {test_image_name}\")\n","            axes[i, 0].axis('off')  # Hide axes for the image\n","        else:\n","            # Plot the test image (query)\n","            axes[0].imshow(test_image)\n","            axes[0].set_title(f\"Query:\\n {test_image_name}\")\n","            axes[0].axis('off')  # Hide axes for the image\n","\n","        # Plot the k nearest images\n","        for j, (index, dist) in enumerate(zip(query_indexes[i], query_distances[i])):\n","            # Load the neighbor image\n","            neighbor_image_path = train_image_paths[index]\n","            neighbor_image = load_img(neighbor_image_path)\n","\n","            # Extract the category (folder name) and name for the neighbor image\n","            neighbor_category = os.path.basename(os.path.dirname(neighbor_image_path))\n","            neighbor_name = os.path.basename(neighbor_image_path)\n","\n","            if (len(test_image_indices)!=1):\n","                # Plot the neighbor image\n","                axes[i, j + 1].imshow(neighbor_image)\n","                axes[i, j + 1].set_title(f\"{neighbor_name}\\n(Dist: {dist:.2f})\")\n","                axes[i, j + 1].axis('off')  # Hide axes for the image\n","            else:\n","                # Plot the neighbor image\n","                axes[j + 1].imshow(neighbor_image)\n","                axes[j + 1].set_title(f\"{neighbor_name}\\n(Dist: {dist:.2f})\")\n","                axes[j + 1].axis('off')  # Hide axes for the image\n","\n","    plt.tight_layout()\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2649,"status":"aborted","timestamp":1738716987759,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"83BdlcDSJOKl"},"outputs":[],"source":["def calculate_anmrr(query_indexes, test_labels, train_labels, k=3):\n","    \"\"\"\n","    Calculate Average Normalized Modified Retrieval Rank (ANMRR)s.\n","    \"\"\"\n","    tests_number = len(query_indexes)  # Number of queries\n","    total_score = 0\n","\n","    for i, query_index in enumerate(query_indexes):\n","        true_label = test_labels[i]  # True label of the current query\n","\n","        # Get the labels of the k nearest neighbors\n","        neighbor_labels = train_labels[query_index]\n","\n","        # Compute AVR(q) - the average rank of relevant documents\n","        relevant_ranks = []\n","        for rank, neighbor_label in enumerate(neighbor_labels):\n","            if neighbor_label == true_label:\n","                relevant_ranks.append(rank + 1)  # Add 1 to convert from 0-indexed to 1-indexed rank\n","\n","        if relevant_ranks:\n","            average_rank_relevant_documents = np.mean(relevant_ranks)  # Average rank of relevant documents\n","        else:\n","            average_rank_relevant_documents = k + 1  # If no relevant documents found, set to K + 1\n","\n","        # Calculate the ANMRR for the query\n","        number_relevant_documents = 1\n","        denominator = 1.25 * k - 0.5 * (1 + number_relevant_documents)\n","        if denominator == 0:  # Handle case when the denominator becomes zero\n","            continue  # Skip this query, as division by zero is not valid\n","\n","        score = (average_rank_relevant_documents - 0.5 * (1 + number_relevant_documents)) / denominator\n","        total_score += score\n","\n","    # Return the final ANMRR score\n","    ANMRR = total_score / tests_number\n","    return ANMRR"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2652,"status":"aborted","timestamp":1738716987763,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"KdW72loUc4WC"},"outputs":[],"source":["def retrieve_and_evaluate_category(kd_tree, category_name, num_images, root_test_folder, category_to_index, test_features):\n","    \"\"\"\n","    Retrieves and evaluates images for a specific category using a KD-Tree.\n","    \"\"\"\n","\n","    print(f\"Retrieving images for category {category_name}...\")\n","\n","    # Get the category index from the category name using the category_to_index mapping\n","    if category_name not in category_to_index:\n","        raise ValueError(f\"Category '{category_name}' not found in the category_to_index mapping.\")\n","\n","    category_index = category_to_index[category_name]\n","\n","    # Find indices of test images belonging to the specified category\n","    test_image_indices = [i for i, label in enumerate(test_labels) if label == category_index]\n","\n","    # Limit the number of images to num_images (if available)\n","    test_image_indices = test_image_indices[:min(num_images, len(test_image_indices))]\n","\n","    # Extract features for the selected test images\n","    test_images = test_features[test_image_indices]\n","\n","    # Perform k-NN search using the KD-Tree\n","    k = 3  # Number of neighbors to retrieve\n","    query_distances, query_indexes = kd_tree.query(test_images, k=k)\n","\n","    # Print retrieved images\n","    print_retrieved_images(train_image_paths, test_image_paths, test_image_indices, query_indexes, query_distances)\n","\n","    # Calculate and print ANMRR\n","    anmrr_value = calculate_anmrr(query_indexes, test_labels[test_image_indices], train_labels, k=k)\n","    print(f\"ANMRR for category {category_name}: {anmrr_value:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"X3wAFhEBZnwP"},"source":["## KD-Tree for MobileNet"]},{"cell_type":"markdown","metadata":{"id":"3_EBfl2yaZA5"},"source":["The kd-tree is created on the train fetures that were extracted earlier; it will be used to retrived most similiar features extracted from query image using mobileNet."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2653,"status":"aborted","timestamp":1738716987766,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"I8JdNXpsGMN0"},"outputs":[],"source":["kd_tree = KDTree(train_features)"]},{"cell_type":"markdown","metadata":{"id":"PXEyBqwbajtf"},"source":["The images are picked with 3 random indices, and their respective feature arrays are retrieved."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2654,"status":"aborted","timestamp":1738716987769,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"qFlL3N1zaRqW"},"outputs":[],"source":["test_images = test_features[test_image_indices]\n","test_images.shape"]},{"cell_type":"markdown","metadata":{"id":"wot5J3pAasBD"},"source":["5 images are retrieved for each one of the test image selected:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2656,"status":"aborted","timestamp":1738716987772,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"waX6AGr3bFRG"},"outputs":[],"source":["distances, indices = kd_tree.query(test_images, k=5)"]},{"cell_type":"markdown","metadata":{"id":"ECiqvkUsaxXl"},"source":["This function takes the result of the kd-tree query and displays dynamically the original image and all of the retrieved images, with useful informations displayed in the titles."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2657,"status":"aborted","timestamp":1738716987774,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"c191QiVhdk4t"},"outputs":[],"source":["print_retrieved_images(train_image_paths, file_list, test_image_indices, indices, distances)"]},{"cell_type":"markdown","metadata":{"id":"ue8xDCVMrLDn"},"source":["## KD-Tree for Triplet loss Siamese Network"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2658,"status":"aborted","timestamp":1738716987776,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"-DgLKOVcz67l"},"outputs":[],"source":["kd_tree_siamese2 = KDTree(train_features_siamese2)"]},{"cell_type":"markdown","metadata":{"id":"Qz0cm375z67m"},"source":["The images are picked with the same exact random indices as before, and their respective feature arrays are retrieved."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2660,"status":"aborted","timestamp":1738716987779,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"h5mpsseEz67m"},"outputs":[],"source":["test_images_siamese2 = test_features_siamese2[test_image_indices]\n","test_images_siamese2.shape"]},{"cell_type":"markdown","metadata":{"id":"E_ToXHzsz67m"},"source":["5 images are retrieved for each one of the 3 test images."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2662,"status":"aborted","timestamp":1738716987782,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"k69ppS1Dz67m"},"outputs":[],"source":["distances_siamese2, indices_siamese2 = kd_tree_siamese2.query(test_images_siamese2, k=5)"]},{"cell_type":"markdown","metadata":{"id":"nssGQNzkz67n"},"source":["This function takes the result of the kd-tree query and displays dynamically the original image and all of the retrieved images, with useful informations displayed in the titles."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2665,"status":"aborted","timestamp":1738716987786,"user":{"displayName":"Francesco Cavallini","userId":"05306891213656518622"},"user_tz":-60},"id":"rdMPxapPz67n"},"outputs":[],"source":["print_retrieved_images(train_image_paths_siamese2, file_list, test_image_indices, indices_siamese2, distances_siamese2)"]},{"cell_type":"markdown","metadata":{"id":"Njkw3jCg5bC6"},"source":["## Small comparaison evaluation:"]},{"cell_type":"markdown","metadata":{"id":"n_7dWbVm5gYP"},"source":["Here we can see that most of the timmes top3 / top2 images retrived are the same in both models. Wich makes perfectly sense as:\n","- first model is raw mobileNet\n","- second model is mobileNet but fine tuned when inserted as encoder into a siamese model whit triplet loss.\n","\n","It is intresting to note that even if models are basically the same some differences can be found after fine tuning. For an example same top3/top2 images have different distances from query image"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["TPO8Ysc0M7xU","QfPntIqNIViF","m3yNB3z0tgOI","feokLf1Glsin"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}